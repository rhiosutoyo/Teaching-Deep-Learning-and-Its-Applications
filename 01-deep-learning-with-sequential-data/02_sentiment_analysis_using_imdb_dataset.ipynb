{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "authorship_tag": "ABX9TyP8oORQ1u7HOJb47LqPVoMU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rhiosutoyo/Teaching-Deep-Learning-and-Its-Applications/blob/main/02_sentiment_analysis_using_imdb_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Sentiment Analysis using IMDB Dataset\n",
        "This example uses the IMDB dataset, which is a commonly used dataset for binary sentiment classification (positive or negative). The example utilize the Keras library with TensorFlow.\n",
        "\n",
        "This code will build, train, and evaluate a simple LSTM-based model for sentiment analysis on the IMDB dataset. You can further tune the hyperparameters and experiment with different architectures to improve performance."
      ],
      "metadata": {
        "id": "w79vsGWpYG2y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Import Libraries"
      ],
      "metadata": {
        "id": "_Iu7dLRTYU2g"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mkRDUwJ2Wzw9"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load and Preprocess Data"
      ],
      "metadata": {
        "id": "VN4U8FdrYWcK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the IMDB dataset\n",
        "max_features = 10000  # Number of words to consider as features\n",
        "maxlen = 300  # Cut texts after this number of words\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "\n",
        "# Pad sequences to ensure uniform input length\n",
        "x_train = pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = pad_sequences(x_test, maxlen=maxlen)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZ8zvbL2W9OT",
        "outputId": "7f179b25-a161-416d-b774-9435a65624aa"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17464789/17464789 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Build the Model"
      ],
      "metadata": {
        "id": "rzmIFbZiYatZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Embedding(max_features, 128, input_length=maxlen),\n",
        "    LSTM(128, dropout=0.2, recurrent_dropout=0.2),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "metadata": {
        "id": "dHB4P6MUW_pL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Compile the Model"
      ],
      "metadata": {
        "id": "6ktt01KcYexw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "mWGDQcsvXBG9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train the Model"
      ],
      "metadata": {
        "id": "V0sv4byAYftz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "epochs = 5\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    validation_data=(x_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HCblFm40XDDy",
        "outputId": "ffa7caea-41b7-4089-daf1-7a61c93467ce"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "782/782 [==============================] - 226s 285ms/step - loss: 0.4654 - accuracy: 0.7830 - val_loss: 0.3605 - val_accuracy: 0.8481\n",
            "Epoch 2/5\n",
            "782/782 [==============================] - 221s 283ms/step - loss: 0.2890 - accuracy: 0.8856 - val_loss: 0.3768 - val_accuracy: 0.8369\n",
            "Epoch 3/5\n",
            "782/782 [==============================] - 220s 282ms/step - loss: 0.2144 - accuracy: 0.9172 - val_loss: 0.3802 - val_accuracy: 0.8330\n",
            "Epoch 4/5\n",
            "782/782 [==============================] - 221s 282ms/step - loss: 0.1695 - accuracy: 0.9365 - val_loss: 0.4007 - val_accuracy: 0.8650\n",
            "Epoch 5/5\n",
            "782/782 [==============================] - 220s 282ms/step - loss: 0.1235 - accuracy: 0.9563 - val_loss: 0.4358 - val_accuracy: 0.8655\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Evaluate the Model"
      ],
      "metadata": {
        "id": "K6YeEvK5YiFW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "score, acc = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
        "print(f'Test score: {score}')\n",
        "print(f'Test accuracy: {acc}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LK8Dt6_cXEt7",
        "outputId": "896a0f11-3aae-4090-8d18-7328421c60c4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 37s 47ms/step - loss: 0.4358 - accuracy: 0.8655\n",
            "Test score: 0.4358404278755188\n",
            "Test accuracy: 0.8654800057411194\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Make Predictions"
      ],
      "metadata": {
        "id": "rcR1-KvtYk6T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the test data\n",
        "predictions = model.predict(x_test)\n",
        "# Convert predictions to binary labels (0 or 1)\n",
        "predicted_labels = (predictions > 0.5).astype(\"int32\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xBs6v3mXGUi",
        "outputId": "c2c4195d-c49a-425a-af9c-bc28d71e4b99"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 40s 52ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Make Predictions (for single sentence)"
      ],
      "metadata": {
        "id": "pP8_XZzZY3xV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "# Function to preprocess and predict the sentiment of a single sentence\n",
        "def predict_sentiment(review, tokenizer, model, maxlen=maxlen):\n",
        "    # Tokenize the review\n",
        "    tokens = tokenizer.texts_to_sequences([review])\n",
        "    # Pad the sequence\n",
        "    tokens_pad = pad_sequences(tokens, maxlen=maxlen)\n",
        "    # Predict the sentiment\n",
        "    prediction = model.predict(tokens_pad)\n",
        "    sentiment = 'positive' if prediction > 0.5 else 'negative'\n",
        "    return sentiment, prediction[0][0]\n",
        "\n",
        "# Prepare a tokenizer using the training data\n",
        "word_index = imdb.get_word_index()\n",
        "reverse_word_index = {value: key for key, value in word_index.items()}\n",
        "tokenizer = Tokenizer(num_words=max_features) # Now Tokenizer is defined\n",
        "tokenizer.word_index = word_index"
      ],
      "metadata": {
        "id": "7qkAAL79Xox0"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Positive Review"
      ],
      "metadata": {
        "id": "2VJvVMI_gl4w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example review\n",
        "pos_review = \"This movie was fantastic! The acting was great and the story was compelling.\"\n",
        "\n",
        "# Predict the sentiment\n",
        "sentiment, score = predict_sentiment(pos_review, tokenizer, model)\n",
        "print(f'Review: {pos_review}')\n",
        "print(f'Sentiment: {sentiment}, Score: {score}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pt6ZYRyAghMW",
        "outputId": "2d8039da-919c-4f24-9f86-46bd3251dfc9"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 53ms/step\n",
            "Review: This movie was fantastic! The acting was great and the story was compelling.\n",
            "Sentiment: positive, Score: 0.845703661441803\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Negative Review"
      ],
      "metadata": {
        "id": "3XEeVUvzgnqk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example review\n",
        "neg_review = \"I was really disappointed with this film. The plot was predictable and boring, and the acting felt forced.\"\n",
        "\n",
        "# Predict the sentiment\n",
        "sentiment, score = predict_sentiment(neg_review, tokenizer, model)\n",
        "print(f'Review: {neg_review}')\n",
        "print(f'Sentiment: {sentiment}, Score: {score}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "StNyp9jzgSbl",
        "outputId": "5f22d54c-c23e-4a12-d374-8c1a1fb1b8b5"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 50ms/step\n",
            "Review: I was really disappointed with this film. The plot was predictable and boring, and the acting felt forced.\n",
            "Sentiment: negative, Score: 0.164226695895195\n"
          ]
        }
      ]
    }
  ]
}